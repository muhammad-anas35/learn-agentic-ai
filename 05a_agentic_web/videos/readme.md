https://www.youtube.com/watch?v=cCv5mdduymA&t=195s


0:00
Hello community. So great that you are back today. Today we look into the future. Let's have a look at the next
0:07
step of the agentic web. Now this will be a complete new technological paradigm
0:13
that we are faced with because the current state-of-the-art ini is defined by a fundamental architectural mismatch
0:20
with the next generation of AI. Why? Because currently we work with LLMs and
0:26
single agents. So, LLMs with an emergent capabilities for complex multi-step reasoning, yet they operate here within
0:33
an internet architecture predicated on a stateless human-driven regress response
0:38
model. Great. This was okay as long as humans use the internet. But how do we
0:45
architect now a new computational paradigm that enables multiple agents to
0:51
transition now from a reactive response role to a proactive goal oriented
0:56
problem solver in a persistent stateful and collaborative manner. Look at this
1:03
future will be if we have an agent a user has your request and the agent says
1:08
hey the user asked me to do the following. So agent will go and said okay I make now a plan the planning here
1:15
of our reasoning models great then do a search an internet search maybe it is
1:22
stuck so it says hey I have to recruit special agents I have to build special agents or I have to buy specialized
1:29
agents from global corporation like Microsoft OpenI or Google then plan
1:35
continues we come to the action phase here we have the tool interaction here
1:40
more collaboration ation with agents here new data stream SQL whatever we have internet searches and we can have
1:47
inter agent discussion rounds here to find the best solution and finally we
1:52
come back here and the agent has now a solution and presents this to the human
1:58
user and you see the human me I just had a question and now I get the answer and
2:04
I don't have to touch anything at all so today's video will I will incorporate
2:11
three brand new publication that were published today and more of the 200 papers that I tried to scan through
2:18
today. Those three were really interesting because they go together.
2:25
First paper will represent the vision of the new web. 77 pages here of detailed
2:32
instruction. What is the next internet generation? Then we will have a look at the implementation of this new idea of
2:38
this vision a blueprint here in action and you are familiar with 90% of this
2:44
and plus we will have then the validation phase we have to evalidate here the performance of multi- aent
2:50
systems and those are the three studies we're going to look at first study is by Shanghai University Hong Kong University
2:58
of Liverpool University of California Berkeley Shanghai Innovative Institute University of California uh Davis
3:05
Virginia Tehen University College London. Second is from Stanford University and George Mason University
3:10
and the third room is from SAP Labs. Great.
3:15
So we have now a systemic evolution that goes now from multi- aent system to a
3:22
semantic web structure based at the next layer on the internet protocol on the
3:28
internet itself to be specific. So let's have a look. What is the vision? The
3:33
prophecy here of a new web emerging here with multiple AI agents.
3:39
They define here that we are entering a new era. The agentic web era, a
3:45
distributed internet ecosystem where autonomous software agents powered by intelligent LLMs or vision language
3:52
model act as the intermediaries to persistently plan, coordinate and
3:58
execute goal directed task on behalf of human users.
4:03
Great. And they say you know we had the PC web where human browse their web of static
4:09
documents here then we had the mobile web phase where human interact with a web of created apps. I don't know I have
4:16
20 apps on my phone and the next one will be an aantic web. Human delegates
4:23
every intent here to a web of autonomous agent.
4:28
In this phase, a human doesn't need any apps anymore because the primary interaction becomes a machine to machine
4:35
a dynamic and orchestrated collaboration to fulfill here the user's goal on a
4:41
complete different complexity level than a human can participate on. So here's what here the first paper
4:47
shows us here the PC web error then the mobile web era now starting 2025 the
4:52
agentic web error AI interfaces multiple AI agent intelligent runtime cloud
4:58
infrastructure key characteristics defined great so therefore let's assume for a moment
5:05
we work with a scenario where classical apps that you have all the time around
5:10
you on your iPad on your iPhone or whatever you use Android phone they might cease to exist because why should
5:17
a human use an app? Why should a human develop an app any further in 2026 when
5:23
we have multi- aent system. So let's go and say listen this AI hype is real. If
5:30
in the US they invested more than a hundred billion dollars just in the development of the next generation here
5:38
there is a momentum building that AI will continue in 2026 and they have to
5:43
come up with something else and they have to bring a rate of intern and rate of investment and now we need
5:51
to see some new market dynamics but let's say that the humans would only use
5:58
apps now and if I have agents on my phone. I don't have to touch my phone anymore. I don't have to open apps,
6:04
anything because agents have a different intelligence workflow. We program it
6:10
today and we see we don't need apps anymore for human interaction. No. So
6:16
there we have it. And the authors tell us we have identified three dimension to this. The first is the intelligence
6:22
dimension. No, this is the agent's brain. It's not anymore about retrieving information, not about rag graph rig or
6:29
anything. No, it is now about multi-step reasoning, the causal reasoning, the
6:34
understanding of the context, the prediction of future possibilities,
6:39
long horizon planning, adaptive continuous learning, contextual understanding. Agent must be able to
6:46
reason about their goals, not just react to prompts or build some app. And then
6:53
we have the complete new interaction dimension. No, if you want this is the nervous system of this new ecosystem.
7:00
How do agents communicate? The old reps HTTP request response is absolutely insufficient. Yeah. So this calls for
7:08
new agent native protocols here a new layer on top of the internet that allows
7:14
here only the agent to discover each other, negotiate, orchestra complex workflow. This is a pure AI layer on the
7:20
internet not for humans anymore. Then of course because somebody has to pay for
7:27
this and this is us the consumers we have the economic dimension of this new technology paradigm because now we bring
7:34
it into the market dimension. This is now becoming a marketplace as agent not
7:39
humans become here the primary consumers of services because the classical
7:44
Googlebased advertising based model like Facebook or WhatsApp this advertising
7:50
based model breaks down it's not anymore working so we need a
7:56
new if you want agent attention economy not the self attention but just the
8:01
agent attention economy and there are currently a lot of New ideas how we can build this, how we can move from
8:08
advertising human have to click on something here. What if agent do all the
8:14
work? Agent are not interested in ads. So we have to come or global corporation have to come up here with new business
8:21
models. This creates a need for new monetization
8:27
models like micro payments for specific API calls orchestrated by your agents
8:33
that you hire or that you rent out for a particular time. And you might say, "Hey, that sounds nice. Great. 77 pages
8:40
here full of details here from multiple university. Great. But how do we actually build it? How close are we?"
8:47
Oh, we are damn close in the implementation phase. We already have the blueprint and we already have it in
8:52
action. And you know there are just two foundational protocols I pick up now from the second publication and you know
8:59
both because I have multiple videos on this. The model context protocol. I'm sure you're familiar maybe you're
9:04
already building with it. Entropic MCP standardizes how the agent interact with tools and all external resources SQL
9:11
database APIs files everything plug and play standard for the tools and of
9:17
course agent to agent communication protocol by Google A2A you know everything with agent Cer have three
9:23
videos on this agent to agent protocol by Google yeah classical multi- aent center you
9:31
know this if you have a system architecture you find in the paper specific a case study rather simple case
9:38
study all the familiar terms if you're into this topic you immediately understand what we're talking about but
9:45
let me give you a simple example if you're a freshman so in the future
9:50
currently already operational a user has a complex multimodal query analyze this
9:56
image of a bridge and query our database for its maintenance history
10:01
now what happens now in a normal old-fashioned classical system multi- aent you have an orchestration agent
10:08
that receives the query this is the boss of the agent yeah using the A2A protocol now this agent discovers and coordinate
10:14
now with specialized domain agent now given the intelligence and the pre-training and the causal reasoning
10:20
and the contextual understanding of this single orchestration agent this agent
10:26
decides now it needs let's say three additional specialist agent yeah it
10:32
needs for example an image agent Or it needs a database query or SQL
10:37
agent or it needs here for historical data here a search agent here in the I
10:43
don't know department of bridge building or whatever it is called you get the idea.
10:49
So we have highly specialized domain agents and they use now the MCP protocol
10:54
to interact with their respective tools vision API SQL database whatever you're
11:00
familiar with those terms everything reported back and the central intelligence of the orchestrator
11:05
synthesizes then everything together and we know it's not working because the poor orchestrator simply overwhelmed we
11:12
have hallucination that is just amazing so what about the validation phase Yeah,
11:18
this is now the third step. We want to make sure, hey, what we built, is it
11:24
working at all? Where are we? 30% success, 50% success, 70%. The science
11:30
of measuring agency. But careful, it's not about a single LLM. It is not about
11:36
a single agent. We are now on a highly dense complex internet network of multi-
11:44
aent system. So what you want to measure now exactly? Yes, of course. The final outcome, this
11:50
is the simplest. No, but think about this. An LLM or a single
11:56
agent evaluation is like testing a car engine here on a bench. But if you go here in agent in interaction with the
12:03
environment with memory with tool use you know it's like testing the entire
12:09
car now on a racetrack or in a city traffic or if you go off-roading you
12:14
assess the performance of the complete system the reliability of the complete system and the safety of the complete
12:20
system in dynamic changing interactive environments and your action your action
12:27
space as a multi- aent system define what you're going to do next and you will have a particular response from the
12:33
environment. So this evaluation routines are completely different to everything
12:39
that we know and at least we will have two dimension what to evaluate and how to evaluate it. Now what to evaluate
12:47
seems easy no the agent behavior the agent capabilities the reliability and the safety and the alignment. Yeah.
12:53
Yeah. For a single construct it would be easy but we have a multi-dimensional
12:59
multicomponent multi-interwoven communication plus we have different action spaces
13:06
here for our transformers in the llms of the brain of the agent.
13:12
So just think about the behavior. Did the agent complete the task? Well that's easy. What was the quality of the
13:19
output? Not so easy anymore. The process was this the right process. Was it
13:24
energy efficient? Was it money specific? How well did the agent use your
13:30
different tools? How well did the agent had a different tool selection accuracy?
13:36
Was it working with two tools that were only appropriate 50% instead of use of
13:42
choosing here one tool with a 100% performance for this particular task? How good was the planning for tool use?
13:49
How good was the reasoning in analyzing the given problem? What is the progress rate? with plan quality,
13:55
reliability. Don't mix up reliability with safety. Reliability here is consistency and
14:02
robustness. If it works one time, you want in a production hall that it works now times. Does it succeed every time?
14:10
Really, how does it handle errors or unexpected changes in the environment? What about if you suddenly we lose an
14:17
API key? safety, alignment, trustworthiness,
14:22
monolithic terms we are standing like little children in front of and we have no idea how to really cut through this
14:30
with a multi- aent system. Dimension two,
14:37
how to evaluate. Now clear, we would all agree in interaction mode. No, we
14:42
evaluate the data, the complexity benchmark that has specific capabilities. We have some benchmark
14:47
already from software engineering task. But my goodness, this is so different to software engineering.
14:54
Just think about the different metrics we could choose here for the computation. And you know what is the
15:00
gold standard? They tell us here in the second paper, the human in the loop.
15:06
And now a new and a compelling story line emerges. No, we're not just building singular AI models. We are
15:14
building now elements that are architected to be an integral part of a
15:19
much more complex agentic dynamic web system. An agentic web, a new digital
15:25
world inhabited not by humans interacting with apps but a world
15:31
inhabited by autonomous agent performing a complete different level of complexity and interaction and reasoning.
15:38
So this aentic web if you want operationalizes now the concept of multiLM powered agents by architecting a
15:46
new decentralized computational layer over the internet.
15:53
We talked about all the protocol problems and the economic models that we need everything from an agent attention
15:59
economy and so on. Can we go a step further? Yes, of
16:05
course. So we have now a transition from a
16:11
system where the humans are in the loop and the human code new apps to a system
16:17
where the humans are on top of the loop delegating their intent the highlevel
16:23
intent to multi- aent system since last two weeks I don't code apps
16:30
anymore we have EI to code small apps or little or tin apps like Google calls it.
16:38
But AI is now coding apps. Why should a human waste time and brain power to code
16:45
apps if AI is doing it? We have to tackle now the next generation of problem that come up. How we can build
16:52
architectures for this and I told you we have three dimensional. the intelligent dimension,
16:58
the interaction dimension, and the economic dimension where you have billions and maybe trillions of dollars
17:05
that you expect the new economy, not as simple.
17:13
Let's go a little bit deeper. You understand that what we are operating here is
17:21
the llm. The core of the agent is if you want only a policy function pine where
17:29
we have a our action on age is the history of the states and the action.
17:34
And now we predict here a new action. And the objective shifts now from
17:41
maximizing a next token prediction likelihood like from a typical singular LLM like GPD5 or whatever you have to
17:49
finding now an optimal trajectory for the complete system that now maximizes
17:55
the expected discounted return for a given goal. G for the complete
18:02
system and just seeing this sentence makes my
18:07
brain explode given the complexity that is on the next deeper level. How we want
18:12
to do this? How you want to build those reward systems for multi- aent system if
18:17
they have an interconnect? So we have to go beyond what we know
18:23
about standard LLMs. No. And the first just think about planning. You remember that the agent here that what is the
18:29
goal or what is the success path? It takes a really complex human task that I
18:35
give to my LLM and it decomposes here the goal into a sequence of sub goals
18:41
and actions that have a lower complexity but therefore it has to have a
18:47
contextual understanding but you remember this is only partially observable.
18:53
So the agent must now have from its pre-training maintain or develop an internal belief state over the true
18:59
state of the environment interacting with the environment. And you know I told you already I don't know in a dozen
19:05
of videos we are talking about partially observable mark of decision processes and this is the theoretical motivation
19:12
here for structured memory system that go beyond the finite uh context windows.
19:18
But think about the action space. We now operate in a much more complex action space now because it does not include
19:25
the text generation but now includes all the action we could use with external tools that are available for us on the
19:30
internet. So the grounding of language and executable action here is or was the
19:37
cornerstone of agency but not any longer. Let's talk about the interaction
19:42
dimension. We talked about here that the agentic web requires here a new protocol stack
19:49
that enables if you want a semantic interoperability and a dynamic composition especially we have multi-
19:55
aent system probably you know at an internet scale
20:00
just think about what agent is allowed to discover here what tool function signature parameter schema or prediction
20:07
here on what sources on the internet think about agent or agent interaction S
20:15
think about the problems we have if we only work here with agent courts. Think
20:20
about the semantic misinterpretation that could happen with structured dialogue for task delegation,
20:27
negotiation and collaborative problem solving between the agents. Yeah, let's
20:32
not talk about this. So what we do now is in the next step of AI if it comes we
20:39
have agent driven RPI calls that now replace the human-driven page views. So
20:45
the complete ad revenue stream system breaks down.
20:50
So we must we must so the global corporation will present to us new
20:55
economic models for our agents. This will be an absolutely fascinating
21:00
time. Scalable planning. How do we scale LLM
21:08
based planning to handle here the combinatorial complexity of the real world long horizon task in the
21:14
interaction with the external environment under uncertainty? What about protocol evolution? What are
21:21
the limits here on the trade-off of MCP and A2A? How can we incorporate mechanisms for trust, reputation or
21:28
verification that goes beyond a single uh yeah you know the classical
21:33
verification or the API keys in the stack. Main problem what everybody's talking
21:39
about continual learning. How can agents continual adapt their policies and their
21:45
internal world models from their entire experience without the catastrophic
21:51
forgetting is happening. If we have CPT or SFT, I will have a new minieries coming up on
21:58
this particular topic. Plus, the science of evaluation will finally come up again
22:04
on a higher level of complexity. How do we create benchmarks that are not only challenging and comprehensive but also
22:12
complex on a complete different level of systems? Now if you are kind of interested those
22:19
are the three papers I selected here published today agentic web weaving here the next web great second agent master
22:28
don't ask me why this has the date of the 8th of July it was published today and July 29 2025 here SAP
22:38
now this evaluation is absolutely fascinating if I go here in multi-system
22:43
configurations And they SAP did a write a really nice paper here on the evaluation objectives
22:50
and they separated this from the process itself. And you have here what is yeah
22:56
maybe I'll show you agent behavior the agent capabilities again reliability
23:02
safety alignment so many open question we have no idea how to respond this we
23:08
have no idea how to design the test for multi- aent collaboration system that test out here not only the single agent
23:15
performance or the two and three agent uh group performance the cluster performance not the complete system
23:21
performance is this really the best configur configuration how you want to build a benchmark for this if we are
23:28
working in a probabilistic environment and not in a deterministic environment
23:34
multi- aent collaboration itself is the Pandora box beautifully just think about
23:39
a financial decision making and structured data analysis now we do have autonomous agent that must exchange
23:46
information negotiate with each other synchronize the decision-m process efficiently and come to a conclusion ion
23:53
without any human interference. And this is maybe your money.
24:00
Collaborative task, collaborative efficiency. How well multiple agents
24:06
share responsibilities. Think about the latest ideas that Open EI has to give EI
24:12
here legal status, legal responsibilities. My goodness, how you evaluate
24:20
distributed task performance on a dynamical level for probabilistic systems.
24:27
Unbelievable times ahead. I told you reliability, safety, beautiful.
24:33
And now I can tell you if you think, hey, this sounds fascinating. Yes, absolutely. But may I just notice that
24:40
this was the sunshine version. And now we come to the reality.
24:50
So all the papers here and let's say the paper number one identifies you the need from the protocols and but we do have a
24:56
protocol kind of war. We have here a bubble of agents that defeats it a
25:02
purpose of seamless interability. Everybody wants to build its own system,
25:07
its own framework. And guess what? And a lot of times they are not interoperable.
25:14
The agents have to correctly interpret the semantic of the agent card in A2A and the tool schemas.
25:22
This is according to the author is really a problem
25:27
because natural language description of functions are notoriously ambitious and even with structured schemas concept
25:34
like book a convenient flight are underspecified and context dependent. This will lead to newer and a really
25:42
interesting class of new bugs that are rooted in a semantic misalignment between a multi- aent configuration
25:50
requiring now a much more sophisticated semantic debugging tool that does not
25:55
even exist yet. Decentralized trust really I mean yeah
26:01
this is the most significant conceptual gap we have right now. How does an agent establish trust with an unknown entity
26:08
on the open internet before delegating a task involving sensitive your personal
26:14
financial data, your medical data or your financial transaction?
26:20
It requires a new stack of decentralized identity, verifiable credentials, and
26:25
maybe maybe we really have to go here to cryptographically secure foundation models. I don't know yet. So a massive
26:33
independent research field and without it the transactional authentic web is a non-stortive for highstake application.
26:40
This is just a play field here a sandbox for some app developer but not a
26:47
marketplace. The orchestrator I already told you we have here the central intelligent of all
26:54
the agentic network. Huh? This architecture places here an immense cognitive and operational burden on a
27:01
single centralized agent. This agent was responsible for all the query de composition, for all the routing and for
27:07
all the synthesis and the model assumes that it is easy to just decompose everything.
27:14
No, in reality the complex query, the decomposition itself can be np hard. The orchestrator can maintain this is the
27:21
hope a perfect real-time model here of all the capabilities and all the current state of the load availability of up
27:28
subordinate agents in real time and yeah it's a centralized model is a cognitive
27:35
bottleneck and is the single most important point of failure that will not scale
27:43
interesting models will come up we have a crippling latency in the cold chain
27:48
think about all the operators or whatever you see already here or whatever you call this an LLM takes over
27:53
your computer and you give it a more complex task and you wait 5 minutes you wait 10 minutes yes of course you have
28:00
latency this described end-to-end workflow represents a long sequential chain of network requests and model
28:06
interferences user server orchestrator A2A domain agent LLM MCP2 API and so on and this is
28:14
just the beginning we are not even talking about any validation step here. So currently the cumulative latency is
28:23
absolutely unacceptable for any interactive application. The authors tell us and we need something new. We
28:28
need techniques like speculative execution. Oh great, we already have if
28:33
you want here probabilistic execution and now we have speculative execution. Oh, I'm looking forward to this. Of
28:40
course, we have to increase the parallelization of all task, subtask and every dependencies and we have to have a
28:46
much better sophisticated caching that would be essential but is currently not addressed at all.
28:52
The nightmare of state management in a distributed system is something oh yeah I leave this over to the expert. It is
28:59
great if you work on distributed system you know what I mean of synchronization without a centralized transaction
29:05
coordinator we have a cascading error propagation. Think about this how what
29:10
we just built. No, the framework's robustness to failure is absolutely unproven. A single failure in a leaf
29:18
node. No, like an agent API key is expiring suddenly on a particular date
29:23
could cause a cascade of exceptions that propagate up to the orchestrator.
29:29
Production grade system would require sophisticated error handling logic at every single layer including context
29:35
aware that retries fallback agents. We have no idea how to build them here in a way that Yeah, you got it.
29:44
Security. Let's talk about security. The implementation security models appear to
29:49
be currently limited to separate API key for different agent. Great. Or maybe an authentification.
29:55
This is absolutely insufficient. If we have a multi- aent system here that operates here autonomous on the
30:02
internet, you know what can happen? data poisoning, prompt injection attacks between the communication of the agent.
30:08
No. So therefore a zero trust architecture where every inter agent
30:14
communication is authenticated, validated, sanitized is really
30:21
non-negotiable for secure agentic web.
30:26
And then the most critical scientific gap. This is a free fall down here
30:33
systems, systemic risk and emergent risks. The entire evaluation framework is
30:39
geared toward assessing single agent or small group performance on well-defined task. Imagine you go out in the real
30:46
world and you have real world interaction here with a multiple group of real agents.
30:54
The most catastrophic risks of a global agentic web will be emergent systemic
30:59
phenomena arising from the interaction of hundred or thousand or even more of
31:05
those AI agents. We have no idea what could happen. We have no methodology to test for
31:13
algorithmic flash crashes. Think about if we have autonomous financial agent.
31:19
They could create a self-reinforcing feedback loop that absolutely could destabilize the market segment.
31:25
Coordinated disinformation at scale. We could have emergent coordination between really malicious agents to generate and
31:33
propagate believable misinformation.
31:38
Systemic goal degradation where agents optimized for local proxy metric for
31:45
your single goal. collectively produce a globally undesirable or unsafe outcome.
31:53
So one department in your company might have success but at the cost of all the
31:58
other departments of your company and therefore in the total the performance
32:03
of your company in total will decrease. So there are problems it's it's it's
32:12
fascinating. So I say welcome to reality. I love to read here these three beautiful
32:19
theoretical AI research report from all the beautiful information on SAP in the
32:24
world. But just think about with what we are dealing.
32:31
We are talking here about here a partially observable mockup decision process where we have a policy executor
32:38
and this is here if you want the the object that we are optimizing in a way
32:44
that we take here a human goal a high level goal that hopefully defines here a
32:51
very specific reward function given here the analysis by this LLM and the agent
32:57
task is now to execute a very particular policy pi Okay, that selects now from a
33:02
much more grown action space specific action that are based on the text, based
33:09
on the tool use, based on the communication to other agent and based on the internal world model
33:15
understanding and predicting the outcome of its future actions based on its
33:20
current belief state of the historic action already undertook. to have a coherent sequence in order to say,
33:28
"Yeah, this is a mathematical optimization procedure. And my job is now to maximize the expected future
33:34
reward function where this reward function can be explicit and implicit and can be mathematically modeled here
33:40
with different complexity models. And maybe you get the feeling that I wanted to
33:46
give you in this video about the future of VI. It's going to be
33:52
amazing, but it's going to be a lot of work ahead of us.
33:58
Yeah. All about the belief state, all about the action space, all about other
34:04
states and the policy. And this little instrument of a policy
34:09
optimization should be the super intelligence for the human race. Are you sure about this?
34:19
Okay. What are the really the next step? The next step of research must now address your non-functional requirements
34:24
that are ultra low latency in the complete system configuration
34:30
distributed state consistency and coherence. We have to do something that it's on the
34:35
security level that maybe we have to go to cryptographic security and we have to find a much better much more robust
34:42
error recovery at scaling those multi- aent system otherwise it's a
34:48
non-starter. I hope you enjoyed this kind of videos and if you want to see more, hey, why
34:54
not subscribe and I see you in my next
